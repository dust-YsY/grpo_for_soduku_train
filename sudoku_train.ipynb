{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-13 18:13:31 [__init__.py:256] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "使用unsloth框架微调Qwen2.5-7B-Instruct模型来解决数独问题\n",
    "这个脚本包含了数据准备、模型训练和评估的完整过程\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TrainingArguments\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7897\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7897\"\n",
    "# os.environ[\"WANDB_PROJECT\"] = \"sudoku_solving_qwen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型参数\n",
    "max_seq_length = 3000  # 可以增加以适应更长的推理过程\n",
    "lora_rank = 16  # 更大的rank = 更智能，但更慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data_path, train_ratio=0.9):\n",
    "    \"\"\"加载并准备训练数据\"\"\"\n",
    "    \n",
    "    # 加载数据集\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sudoku_dataset = json.load(f)\n",
    "    \n",
    "    print(f\"加载了 {len(sudoku_dataset)} 条数独数据\")\n",
    "    \n",
    "    # 构建训练数据集\n",
    "    training_data = []\n",
    "\n",
    "        # 添加系统提示\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    用以下格式回答问题:\n",
    "    <think>推理过程</think>\n",
    "    <answer>答案</answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    for example in sudoku_dataset:\n",
    "        question = example[\"question\"]\n",
    "        answer = example[\"answer\"]\n",
    "        \n",
    "        # 构建Qwen2.5的输入格式\n",
    "        prompt = f\"<|im_start|>system\\n{SYSTEM_PROMPT}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "        full_prompt = prompt + answer + \"<|im_end|>\"\n",
    "        \n",
    "        training_data.append({\"text\": full_prompt})\n",
    "    \n",
    "    # 转换为HuggingFace数据集格式\n",
    "    random.shuffle(training_data)  # 随机打乱数据\n",
    "    train_size = int(len(training_data) * train_ratio)  \n",
    "    train_dataset = Dataset.from_list(training_data[:train_size])\n",
    "    eval_dataset = Dataset.from_list(training_data[train_size:])\n",
    "    \n",
    "    print(f\"训练集大小: {len(train_dataset)}\")\n",
    "    print(f\"验证集大小: {len(eval_dataset)}\")\n",
    "    \n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name=\"Qwen/Qwen2.5-3B-Instruct\"):\n",
    "    \"\"\"加载基础模型并配置LoRA\"\"\"\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
    "    )\n",
    "\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "        target_modules = [\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        ], # Remove QKVO if out of memory\n",
    "        lora_alpha = lora_rank,\n",
    "        use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "        random_state = 3407,\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "def setup_trainer(model, tokenizer, train_dataset):\n",
    "    \"\"\"设置训练器\"\"\"\n",
    "    trainer = SFTTrainer(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        train_dataset = train_dataset,\n",
    "        dataset_text_field = \"text\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dataset_num_proc = 2,\n",
    "        packing = False, # Can make training 5x faster for short sequences.\n",
    "        args = TrainingArguments(\n",
    "            per_device_train_batch_size = 2,\n",
    "            gradient_accumulation_steps = 4,\n",
    "            warmup_steps = 5,\n",
    "            # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "            max_steps = 60,\n",
    "            learning_rate = 2e-4,\n",
    "            fp16 = not is_bfloat16_supported(),\n",
    "            bf16 = is_bfloat16_supported(),\n",
    "            logging_steps = 1,\n",
    "            optim = \"adamw_8bit\",\n",
    "            weight_decay = 0.01,\n",
    "            lr_scheduler_type = \"linear\",\n",
    "            seed = 3407,\n",
    "            output_dir = \"outputs\",\n",
    "            report_to = \"none\", # Use this for WandB etc\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tokenizer, test_question):\n",
    "    \"\"\"测试模型在给定问题上的表现\"\"\"\n",
    "\n",
    "    # 添加系统提示\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    用以下格式回答问题:\n",
    "    <think>推理过程</think>\n",
    "    <answer>答案</answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"<|im_start|>system\\n{SYSTEM_PROMPT}<|im_end|>\\n<|im_start|>user\\n{test_question}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "    # alpaca_prompt = Copied from above\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        prompt\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 3000, use_cache = True)\n",
    "    generated_text = tokenizer.batch_decode(outputs)\n",
    "    \n",
    "    # 提取生成文本中的助手回复部分\n",
    "    assistant_response = generated_text[0].split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0]\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataset, num_samples=5):\n",
    "    \"\"\"评估模型在数据集上的表现，重点关注是否生成了<think>和<answer>标签\"\"\"\n",
    "\n",
    "    # 添加系统提示\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    用以下格式回答问题:\n",
    "    <think>推理过程</think>\n",
    "    <answer>答案</answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    # 随机选择样本\n",
    "    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "    \n",
    "    results = []\n",
    "    for idx in indices:\n",
    "        example = dataset[idx]\n",
    "        text = example[\"text\"]\n",
    "        \n",
    "        # 提取问题\n",
    "        question = text.split(\"<|im_start|>user\\n\")[1].split(\"<|im_end|>\")[0]\n",
    "        prompt = f\"<|im_start|>system\\n{SYSTEM_PROMPT}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "        \n",
    "        # alpaca_prompt = Copied from above\n",
    "        FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            prompt\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "        outputs = model.generate(**inputs, max_new_tokens = 3000, use_cache = True)\n",
    "        generated_text = tokenizer.batch_decode(outputs)\n",
    "        \n",
    "        # 提取答案\n",
    "        answer = generated_text[0].split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0]\n",
    "        \n",
    "        # 检查是否包含 <think> 和 <answer> 标记\n",
    "        has_think_tag = \"<think>\" in answer and \"</think>\" in answer\n",
    "        has_answer_tag = \"<answer>\" in answer and \"</answer>\" in answer\n",
    "        \n",
    "        # 收集结果\n",
    "        results.append({\n",
    "            \"has_think_tag\": has_think_tag,\n",
    "            \"has_answer_tag\": has_answer_tag,\n",
    "            \"answer\": answer,\n",
    "        })\n",
    "    \n",
    "    # 计算统计数据\n",
    "    stats = {\n",
    "        \"total_samples\": len(results),\n",
    "        \"samples_with_think_tag\": sum(1 for r in results if r[\"has_think_tag\"]),\n",
    "        \"samples_with_answer_tag\": sum(1 for r in results if r[\"has_answer_tag\"]),\n",
    "        \"samples_with_both_tags\": sum(1 for r in results if r[\"has_think_tag\"] and r[\"has_answer_tag\"]),\n",
    "    }\n",
    "\n",
    "    return results, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(original_model, original_tokenizer, finetuned_model, finetuned_tokenizer, test_question):\n",
    "    \n",
    "    # 使用原始模型生成答案\n",
    "    original_answer = test_model(original_model, original_tokenizer, test_question)\n",
    "    \n",
    "    # 使用微调后的模型生成答案\n",
    "    finetuned_answer = test_model(finetuned_model, finetuned_tokenizer, test_question)\n",
    "    \n",
    "    return original_answer, finetuned_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载了 50 条数独数据\n",
      "训练集大小: 45\n",
      "验证集大小: 5\n"
     ]
    }
   ],
   "source": [
    "# 加载和准备数据\n",
    "train_dataset, eval_dataset = load_and_prepare_data(\"reasoning_sft_dataset/sudoku_reasoning_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载基础模型\n",
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试原始模型\n",
    "if len(eval_dataset) > 0:\n",
    "    test_example = eval_dataset[3][\"text\"]\n",
    "    test_question = test_example.split(\"<|im_start|>user\\n\")[1].split(\"<|im_end|>\")[0]\n",
    "    original_response = test_model(model, tokenizer, test_question)\n",
    "    print(\"问题：\")\n",
    "    print(test_question)\n",
    "    print(\"原始模型回答示例:\")\n",
    "    print(original_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 设置训练器\n",
    "# trainer = setup_trainer(model, tokenizer, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 开始训练\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存模型\n",
    "output_dir = \"output/sudoku_solving_qwen3b_sft\"\n",
    "# trainer.save_model(output_dir)\n",
    "# print(f\"模型已保存到: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  加载微调后的模型\n",
    "print(\"\\n步骤7: 加载微调后的模型...\")\n",
    "finetuned_model, finetuned_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=output_dir,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    fast_inference=True,\n",
    "    gpu_memory_utilization=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试微调后的模型\n",
    "print(\"\\n步骤8: 测试微调后的模型...\")\n",
    "if len(eval_dataset) > 0:\n",
    "    test_example = eval_dataset[3][\"text\"]\n",
    "    test_question = test_example.split(\"<|im_start|>user\\n\")[1].split(\"<|im_end|>\")[0]\n",
    "    finetuned_response = test_model(finetuned_model, finetuned_tokenizer, test_question)\n",
    "    print(\"问题：\")\n",
    "    print(test_question)\n",
    "    print(\"sft模型回答示例:\")\n",
    "    print(finetuned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载原始模型进行评估\n",
    "print(\"加载原始模型进行评估...\")\n",
    "original_model, original_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    "    fast_inference = True,\n",
    "    gpu_memory_utilization = 0.8,\n",
    ")\n",
    "\n",
    "original_results, original_stats = evaluate_model(original_model, original_tokenizer, eval_dataset, num_samples=1)\n",
    "print(\"原始模型评估结果:\")\n",
    "print(\"包含<think>标签的样本数:\", original_stats[\"samples_with_think_tag\"])\n",
    "print(\"包含<answer>标签的样本数:\", original_stats[\"samples_with_answer_tag\"])\n",
    "print(\"同时包含两个标签的样本数:\", original_stats[\"samples_with_both_tags\"])\n",
    "print(\"\\n原始模型回答示例:\")\n",
    "print(original_results[0][\"answer\"])\n",
    "\n",
    "print(\"\\n评估微调后的模型...\")\n",
    "finetuned_results, finetuned_stats = evaluate_model(finetuned_model, finetuned_tokenizer, eval_dataset, num_samples=1)\n",
    "print(\"微调后模型评估结果:\")\n",
    "print(\"包含<think>标签的样本数:\", finetuned_stats[\"samples_with_think_tag\"])\n",
    "print(\"包含<answer>标签的样本数:\", finetuned_stats[\"samples_with_answer_tag\"])\n",
    "print(\"同时包含两个标签的样本数:\", finetuned_stats[\"samples_with_both_tags\"])\n",
    "print(\"\\n微调后模型回答示例:\")\n",
    "print(finetuned_results[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤10: 创建一个新的测试数独\n",
    "new_sudoku = \"\"\"以下是一个数独游戏，在9乘9的81宫格中，数字的顺序分别为：\n",
    "8 6 3 | 2 0 4 | 9 1 5\n",
    "1 5 9 | 6 3 8 | 7 4 2\n",
    "4 2 7 | 5 9 1 | 3 8 6\n",
    "------+-------+------\n",
    "9 1 6 | 8 2 3 | 5 7 4\n",
    "7 4 5 | 1 6 9 | 2 3 8\n",
    "3 8 2 | 4 5 7 | 6 9 1\n",
    "------+-------+------\n",
    "6 0 8 | 3 4 2 | 1 5 7\n",
    "5 7 1 | 9 8 6 | 4 2 3\n",
    "2 3 4 | 7 1 5 | 8 6 9\n",
    "其中0代表空缺的数字，需要你去填写，请你完成这个数独游戏，并输出相同格式的答案。\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "original_new_answer, finetuned_new_answer = compare_models(\n",
    "    model, tokenizer, finetuned_model, finetuned_tokenizer, new_sudoku\n",
    ")\n",
    "\n",
    "print(\"新的数独问题:\")\n",
    "print(new_sudoku)\n",
    "print(\"\\n原始模型回答:\")\n",
    "print(original_new_answer[:3000] + \"...\" if len(original_new_answer) > 3000 else original_new_answer)\n",
    "\n",
    "\n",
    "finetuned_new_answer = test_model(finetuned_model, finetuned_tokenizer, test_question)\n",
    "\n",
    "print(\"\\n微调后模型回答:\")\n",
    "print(finetuned_new_answer[:3000] + \"...\" if len(finetuned_new_answer) > 3000 else finetuned_new_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def format_sudoku(puzzle_str):\n",
    "    \"\"\"将81个字符的数独字符串转换为9x9矩阵格式\"\"\"\n",
    "    if len(puzzle_str) != 81:\n",
    "        print(f\"警告: 数独字符串长度不是81，而是{len(puzzle_str)}，无法格式化。\")\n",
    "        return None\n",
    "\n",
    "    grid = np.array(list(puzzle_str)).reshape(9, 9)\n",
    "    formatted = []\n",
    "    for i in range(9):\n",
    "        row = \" \".join(grid[i, :3]) + \" | \" + \" \".join(grid[i, 3:6]) + \" | \" + \" \".join(grid[i, 6:])\n",
    "        formatted.append(row)\n",
    "        if i == 2 or i == 5:\n",
    "            formatted.append(\"------+-------+------\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "def get_sudoku_dataset(split=\"train\") -> Dataset:\n",
    "    \"\"\"加载数独数据集并转换为GRPO训练所需的格式\"\"\"\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(\"dataset/sudoku_cluewise.csv\")\n",
    "    \n",
    "    # 筛选线索数量大于等于78的数据\n",
    "    df = df[df['clue_numbers'] >= 78]\n",
    "    \n",
    "    # 如果数据量超过500，随机选择500条\n",
    "    if len(df) > 500:\n",
    "        df = df.sample(n=500, random_state=42)\n",
    "    \n",
    "    print(f\"筛选后数据集大小: {len(df)}\")\n",
    "    \n",
    "    # 转换数据格式\n",
    "    def transform_data(row):\n",
    "        puzzle = row['quizzes']\n",
    "        solution = row['solutions']\n",
    "        \n",
    "        # 格式化数独谜题\n",
    "        formatted_puzzle = format_sudoku(puzzle)\n",
    "        if formatted_puzzle is None:\n",
    "            return None\n",
    "            \n",
    "        # 构建问题\n",
    "        question = f\"以下是一个数独游戏，在9乘9的81宫格中，数字的顺序分别为：\\n{formatted_puzzle}\\n其中0代表空缺的数字，需要你去填写，请你完成这个数独游戏，并输出相同格式的答案。\"\n",
    "\n",
    "        # 添加系统提示\n",
    "        SYSTEM_PROMPT = \"\"\"\n",
    "        用以下格式回答问题:\n",
    "        <think>推理过程</think>\n",
    "        <answer>答案</answer>\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\n",
    "            'prompt': [\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                {'role': 'user', 'content': question}\n",
    "            ],\n",
    "            'answer': format_sudoku(solution)\n",
    "        }\n",
    "    \n",
    "    # 转换数据\n",
    "    transformed_data = [transform_data(row) for _, row in df.iterrows()]\n",
    "    transformed_data = [x for x in transformed_data if x is not None]\n",
    "    \n",
    "    # 转换为Dataset格式\n",
    "    dataset = Dataset.from_list(transformed_data)\n",
    "    \n",
    "    # 划分训练集和验证集\n",
    "    if split == \"train\":\n",
    "        dataset = dataset.select(range(int(0.9 * len(dataset))))\n",
    "    else:\n",
    "        dataset = dataset.select(range(int(0.9 * len(dataset)), len(dataset)))\n",
    "    \n",
    "    print(f\"{split}集大小: {len(dataset)}\")\n",
    "    return dataset\n",
    "\n",
    "# 提取<answer>标签中的内容\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    if \"<answer>\" not in text or \"</answer>\" not in text:\n",
    "        return \"\"\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "# 正确性奖励函数\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    \n",
    "    # 提取答案，如果提取失败则返回空字符串\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    \n",
    "    # print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    \n",
    "    # 比较答案，空字符串直接返回0分\n",
    "    return [2.0 if r and r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "# 软格式奖励函数\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<think>.*?</think>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    \n",
    "    rewards = []\n",
    "    \n",
    "    print(\"\\n=== Soft Format Reward Debug ===\")\n",
    "    for i, response in enumerate(responses):\n",
    "        contains_think_open = \"<think>\" in response\n",
    "        contains_think_close = \"</think>\" in response\n",
    "        contains_answer_open = \"<answer>\" in response\n",
    "        contains_answer_close = \"</answer>\" in response\n",
    "        \n",
    "        match = re.match(pattern, response, re.DOTALL)\n",
    "        \n",
    "        # 计算奖励\n",
    "        if match:\n",
    "            reward = 1.0  # 完全匹配正则，直接给满分\n",
    "        else:\n",
    "            reward = (\n",
    "                (0.15 if contains_think_open else 0) +\n",
    "                (0.15 if contains_think_close else 0) +\n",
    "                (0.15 if contains_answer_open else 0) +\n",
    "                (0.15 if contains_answer_close else 0)\n",
    "            )\n",
    "        \n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # 调试信息\n",
    "        print(f\"\\nResponse {i}:\")\n",
    "        print(f\"Contains <think>: {contains_think_open}\")\n",
    "        print(f\"Contains </think>: {contains_think_close}\")\n",
    "        print(f\"Contains <answer>: {contains_answer_open}\")\n",
    "        print(f\"Contains </answer>: {contains_answer_close}\")\n",
    "        print(f\"Pattern match: {match}\")\n",
    "        print(f\"Final Reward: {reward}\")\n",
    "\n",
    "    return rewards\n",
    "\n",
    "# 格式正确性奖励函数\n",
    "def format_correctness_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the answer follows the correct format.\"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    \n",
    "    print(\"\\n=== Format Correctness Reward Debug ===\")\n",
    "    for i, response in enumerate(responses):\n",
    "        print(f\"\\nResponse {i}:\")\n",
    "        # 提取<answer>标签中的内容\n",
    "        answer = extract_xml_answer(response)\n",
    "        \n",
    "        # 如果提取失败，直接返回0分\n",
    "        if not answer:\n",
    "            print(\"Failed to extract answer from XML tags\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        print(\"Extracted answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "        # 检查格式是否正确\n",
    "        lines = answer.strip().split('\\n')\n",
    "        print(f\"Number of lines: {len(lines)}\")\n",
    "        \n",
    "        if len(lines) != 11:  # 9行数字 + 2行分隔线\n",
    "            print(f\"Wrong number of lines: expected 11, got {len(lines)}\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # 检查每行的格式\n",
    "        format_correct = True\n",
    "        for i, line in enumerate(lines):\n",
    "            if i in [3, 7]:  # 分隔线\n",
    "                if line != \"------+-------+------\":\n",
    "                    print(f\"Wrong separator line at index {i}: {line}\")\n",
    "                    format_correct = False\n",
    "                    break\n",
    "            else:  # 数字行\n",
    "                parts = line.split('|')\n",
    "                if len(parts) != 3:\n",
    "                    print(f\"Wrong number of parts at line {i}: {line}\")\n",
    "                    format_correct = False\n",
    "                    break\n",
    "                for j, part in enumerate(parts):\n",
    "                    if len(part.strip().split()) != 3:\n",
    "                        print(f\"Wrong number of numbers in part {j} of line {i}: {part}\")\n",
    "                        format_correct = False\n",
    "                        break\n",
    "        \n",
    "        print(f\"Format correct: {format_correct}\")\n",
    "        rewards.append(1.0 if format_correct else 0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "def sudoku_validity_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the answer is a valid Sudoku solution.\"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    \n",
    "    print(\"\\n=== Sudoku Validity Reward Debug ===\")\n",
    "    for i, response in enumerate(responses):\n",
    "        print(f\"\\nResponse {i}:\")\n",
    "        # 提取<answer>标签中的内容\n",
    "        answer = extract_xml_answer(response)\n",
    "        \n",
    "        # 如果提取失败，直接返回0分\n",
    "        if not answer:\n",
    "            print(\"Failed to extract answer from XML tags\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 将答案转换为9x9矩阵\n",
    "            lines = answer.strip().split('\\n')\n",
    "            grid = []\n",
    "            for line in lines:\n",
    "                if line == \"------+-------+------\":\n",
    "                    continue\n",
    "                # 移除分隔符并分割数字\n",
    "                numbers = line.replace('|', '').split()\n",
    "                grid.append([int(n) for n in numbers])\n",
    "            \n",
    "            if len(grid) != 9 or any(len(row) != 9 for row in grid):\n",
    "                print(\"Invalid grid dimensions\")\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # 检查每行\n",
    "            row_rewards = 0\n",
    "            for row_idx, row in enumerate(grid):\n",
    "                if set(row) == set(range(1, 10)):\n",
    "                    row_rewards += 0.1\n",
    "                    print(f\"Row {row_idx + 1} is valid\")\n",
    "                else:\n",
    "                    print(f\"Row {row_idx + 1} is invalid: {row}\")\n",
    "            \n",
    "            # 检查每列\n",
    "            col_rewards = 0\n",
    "            for col in range(9):\n",
    "                column = [grid[row][col] for row in range(9)]\n",
    "                if set(column) == set(range(1, 10)):\n",
    "                    col_rewards += 0.1\n",
    "                    print(f\"Column {col + 1} is valid\")\n",
    "                else:\n",
    "                    print(f\"Column {col + 1} is invalid: {column}\")\n",
    "            \n",
    "            # 检查每个3x3小框\n",
    "            box_rewards = 0\n",
    "            for box_row in range(0, 9, 3):\n",
    "                for box_col in range(0, 9, 3):\n",
    "                    # 提取3x3小框中的数字\n",
    "                    box = []\n",
    "                    for i in range(3):\n",
    "                        for j in range(3):\n",
    "                            box.append(grid[box_row + i][box_col + j])\n",
    "                    if set(box) == set(range(1, 10)):\n",
    "                        box_rewards += 0.1\n",
    "                        print(f\"Box at ({box_row}, {box_col}) is valid\")\n",
    "                    else:\n",
    "                        print(f\"Box at ({box_row}, {box_col}) is invalid: {box}\")\n",
    "            \n",
    "            # 总奖励为行奖励、列奖励和小框奖励之和\n",
    "            total_reward = row_rewards + col_rewards + box_rewards\n",
    "            print(f\"Total reward: {total_reward} (rows: {row_rewards}, columns: {col_rewards}, boxes: {box_rewards})\")\n",
    "            rewards.append(total_reward)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing grid: {str(e)}\")\n",
    "            rewards.append(0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "# 线索保留和空单元格填充奖励函数\n",
    "def clue_preservation_reward_func(prompts, completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if original clues are preserved and rewards correct empty cell filling.\"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    questions = [prompt[-1][\"content\"] for prompt in prompts]\n",
    "    rewards = []\n",
    "    \n",
    "    print(\"\\n=== Clue Preservation and Empty Cell Reward Debug ===\")\n",
    "    for i, (response, question) in enumerate(zip(responses, questions)):\n",
    "        print(f\"\\nResponse {i}:\")\n",
    "        \n",
    "        # 提取答案\n",
    "        answer = extract_xml_answer(response)\n",
    "        if not answer:\n",
    "            print(\"Failed to extract answer from XML tags\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # 从问题中提取原始数独\n",
    "            original_grid = []\n",
    "            for line in question.split('\\n'):\n",
    "                if '|' in line and not line.startswith('------'):\n",
    "                    # 移除分隔符并分割数字\n",
    "                    numbers = line.replace('|', '').split()\n",
    "                    original_grid.append([int(n) if n != '0' else 0 for n in numbers])\n",
    "            \n",
    "            # 从答案中提取填充后的数独\n",
    "            filled_grid = []\n",
    "            for line in answer.split('\\n'):\n",
    "                if '|' in line and not line.startswith('------'):\n",
    "                    # 移除分隔符并分割数字\n",
    "                    numbers = line.replace('|', '').split()\n",
    "                    filled_grid.append([int(n) for n in numbers])\n",
    "            \n",
    "            # 检查原始线索是否保持不变\n",
    "            clue_preserved = True\n",
    "            empty_cells = 0\n",
    "            correct_fills = 0\n",
    "            \n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    if original_grid[i][j] != 0:  # 这是一个原始线索\n",
    "                        if original_grid[i][j] != filled_grid[i][j]:\n",
    "                            clue_preserved = False\n",
    "                            print(f\"Original clue changed at position ({i}, {j}): {original_grid[i][j]} -> {filled_grid[i][j]}\")\n",
    "                    else:  # 这是一个空单元格\n",
    "                        empty_cells += 1\n",
    "                        if filled_grid[i][j] in range(1, 10):  # 确保填充的是有效数字\n",
    "                            correct_fills += 1\n",
    "            \n",
    "            if not clue_preserved:\n",
    "                print(\"Original clues were not preserved\")\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # 计算奖励\n",
    "            if empty_cells > 0:\n",
    "                reward = correct_fills / empty_cells\n",
    "                print(f\"Empty cells: {empty_cells}, Correct fills: {correct_fills}, Reward: {reward}\")\n",
    "            else:\n",
    "                reward = 1.0  # 如果没有空单元格，说明所有线索都正确\n",
    "                print(\"No empty cells to fill\")\n",
    "            \n",
    "            rewards.append(reward)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing grids: {str(e)}\")\n",
    "            rewards.append(0.0)\n",
    "    \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "train_dataset = get_sudoku_dataset(split=\"train\")\n",
    "eval_dataset = get_sudoku_dataset(split=\"eval\")\n",
    "\n",
    "# # 初始化wandb\n",
    "# wandb.init(\n",
    "#     project=\"sudoku_solving_qwen\",\n",
    "#     config={\n",
    "#         \"model_name\": \"Qwen2.5-0.5B-Instruct\",\n",
    "#         \"max_seq_length\": max_seq_length,\n",
    "#         \"lora_rank\": lora_rank,\n",
    "#         \"learning_rate\": 5e-6,\n",
    "#         \"batch_size\": 1,\n",
    "#         \"gradient_accumulation_steps\": 1,\n",
    "#         \"num_generations\": 6,\n",
    "#         \"max_steps\": 250,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# training_args = GRPOConfig(\n",
    "#     learning_rate = 5e-6,\n",
    "#     adam_beta1 = 0.9,\n",
    "#     adam_beta2 = 0.99,\n",
    "#     weight_decay = 0.1,\n",
    "#     warmup_ratio = 0.1,\n",
    "#     lr_scheduler_type = \"cosine\",\n",
    "#     optim = \"paged_adamw_8bit\",\n",
    "#     logging_steps = 1,\n",
    "#     per_device_train_batch_size = 1,\n",
    "#     gradient_accumulation_steps = 1,\n",
    "#     num_generations = 6,\n",
    "#     max_prompt_length = max_seq_length // 2,\n",
    "#     max_completion_length = max_seq_length // 2,\n",
    "#     max_steps = 500,\n",
    "#     save_steps = 250,\n",
    "#     max_grad_norm = 0.1,\n",
    "#     report_to = \"wandb\",  # 启用wandb报告\n",
    "#     output_dir = \"output/sudoku_solving_qwen3b_grpo\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个自定义的回调类来记录奖励函数的结果\n",
    "from transformers import TrainerCallback\n",
    "class RewardCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.log_history:\n",
    "            # 记录最新的训练指标\n",
    "            for log in state.log_history:\n",
    "                if isinstance(log, dict):\n",
    "                    wandb.log(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = GRPOTrainer(\n",
    "#     model = finetuned_model,\n",
    "#     processing_class = finetuned_tokenizer,\n",
    "#     reward_funcs = [\n",
    "#         soft_format_reward_func,\n",
    "#         correctness_reward_func,\n",
    "#         format_correctness_reward_func,\n",
    "#         sudoku_validity_reward_func,\n",
    "#         clue_preservation_reward_func,\n",
    "#     ],\n",
    "#     args = training_args,\n",
    "#     train_dataset = train_dataset,\n",
    "#     callbacks=[RewardCallback()],  # 添加自定义回调\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 开始训练\n",
    "# trainer.train()\n",
    "\n",
    "# # 关闭wandb\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存模型\n",
    "output_dir = \"output/sudoku_solving_qwen3b_grpo\"\n",
    "# trainer.save_model(output_dir)\n",
    "# print(f\"模型已保存到: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "步骤7: 加载微调后的模型...\n",
      "==((====))==  Unsloth 2025.3.18: Fast Qwen2 patching. Transformers: 4.50.0. vLLM: 0.8.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 2080 Ti. Num GPUs = 1. Max memory: 21.657 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit with actual GPU utilization = 58.33%\n",
      "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 21.66 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 3000. Num Sequences = 192.\n",
      "Unsloth: vLLM's KV Cache can use up to 6.5 GB. Also swap space = 4 GB.\n",
      "WARNING 04-13 18:17:00 [config.py:2599] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-13 18:17:03 [config.py:583] This model supports multiple tasks: {'reward', 'classify', 'score', 'embed', 'generate'}. Defaulting to 'generate'.\n",
      "WARNING 04-13 18:17:03 [arg_utils.py:1765] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.0.self_attn', 'model.layers.1.self_attn', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.4.mlp', 'model.layers.25.mlp', 'model.layers.26.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 04-13 18:17:03 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=3000, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n",
      "INFO 04-13 18:17:04 [cuda.py:234] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 04-13 18:17:04 [cuda.py:282] Using XFormers backend.\n",
      "INFO 04-13 18:17:04 [parallel_state.py:967] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-13 18:17:04 [model_runner.py:1110] Starting to load model unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit...\n",
      "INFO 04-13 18:17:04 [loader.py:1137] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 04-13 18:17:06 [weight_utils.py:257] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae115754a3db4f5694f04019a4e9cc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb92bd237494472b64c0de9fb046ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 18:17:09 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 04-13 18:17:09 [model_runner.py:1146] Model loading took 7.0262 GB and 4.281014 seconds\n",
      "INFO 04-13 18:17:10 [worker.py:267] Memory profiling takes 1.54 seconds\n",
      "INFO 04-13 18:17:10 [worker.py:267] the current vLLM instance can use total_gpu_memory (21.66GiB) x gpu_memory_utilization (0.58) = 12.63GiB\n",
      "INFO 04-13 18:17:10 [worker.py:267] model weights take 7.03GiB; non_torch_memory takes 0.02GiB; PyTorch activation peak memory takes 1.06GiB; the rest of the memory reserved for KV Cache is 4.52GiB.\n",
      "INFO 04-13 18:17:10 [executor_base.py:111] # cuda blocks: 5288, # CPU blocks: 4681\n",
      "INFO 04-13 18:17:10 [executor_base.py:116] Maximum concurrency for 3000 tokens per request: 28.20x\n",
      "INFO 04-13 18:17:12 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|█████████████████████████████████████████████████████████████████| 27/27 [00:11<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 18:17:24 [model_runner.py:1570] Graph capturing finished in 12 secs, took 0.55 GiB\n",
      "INFO 04-13 18:17:24 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 15.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.3.18 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "#  加载微调后的模型\n",
    "print(\"\\n步骤7: 加载微调后的模型...\")\n",
    "finetuned_model, finetuned_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=output_dir,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    fast_inference=True,\n",
    "    gpu_memory_utilization=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "步骤8: 测试微调后的模型...\n",
      "问题：\n",
      "以下是一个数独游戏，在9乘9的81宫格中，数字的顺序分别为：\n",
      "3 7 4 | 8 5 1 | 6 2 9\n",
      "1 5 8 | 6 9 2 | 4 3 7\n",
      "2 9 6 | 4 7 3 | 8 1 5\n",
      "------+-------+------\n",
      "8 1 7 | 5 2 6 | 9 4 3\n",
      "6 2 5 | 9 3 4 | 0 8 1\n",
      "4 3 9 | 7 1 8 | 5 6 2\n",
      "------+-------+------\n",
      "9 4 2 | 3 8 7 | 1 5 6\n",
      "5 6 1 | 2 4 9 | 3 7 8\n",
      "7 8 3 | 1 6 5 | 2 9 4\n",
      "其中0代表空缺的数字，需要你去填写，请你完成这个数独游戏，并输出相同格式的答案。\n",
      "sft模型回答示例:\n",
      "<think>嗯，我现在要解决这个数独问题。首先，我需要仔细观察题目给出的数独布局，找出所有0的位置，然后根据数独的规则来推断出正确的数字。数独的规则是每一行、每一列以及每个3x3的小九宫格内数字1-9不能重复。\n",
      "\n",
      "首先，我先将题目中的数独结构整理清楚。数独的结构是9x9的，分为9个3x3的小宫格。现在，我需要找出所有0的位置，并逐一解决。\n",
      "\n",
      "观察给出的数独，我注意到第6行的第7列有一个0，也就是坐标（6,7）的位置。其他位置都是已填好的数字。现在，我需要确定这个0应该填什么数字。\n",
      "\n",
      "根据数独的规则，每一行、列和小宫格都必须包含1-9的数字，不能重复。所以，我需要检查第6行、第7列以及第5-7行的中间小宫格（即第5-7行，第7-9列）来确定0的位置应该填什么数字。\n",
      "\n",
      "先看第6行，已有的数字是4,3,9,7,1,8,5,6,2，缺少的数字是0，所以这个位置应该填0，但这里可能有误，因为0的位置应该填其他数字。所以，我需要仔细检查。\n",
      "\n",
      "现在，我需要检查第6行的数字，看看是否有重复。当前第6行的数字是4,3,9,7,1,8,0,5,6。所以，缺少的数字是2。因此，第6行第7列的0应该填2。这样，第6行就完整了。\n",
      "\n",
      "接下来，我需要检查第7列是否有其他数字，确保没有重复。第7列的数字是6,4,8,9,0,5,1,3,2。这里0的位置在第6行，所以填2是正确的。\n",
      "\n",
      "然后，我需要检查第5-7行的中间小宫格（第5-7行，第7-9列）是否有重复。当前这个小宫格中的数字是0（即第6行第7列）、8、1；第7行第7列是1，第8行第7列是3。所以，这个小宫格中已有的数字是1,3,8,1,0,5,3,7,2。所以，缺少的数字是4,6。但因为第6行第7列填2，所以这里没有问题。\n",
      "\n",
      "因此，0的位置应该填2。现在，整个数独就完成了。</think>\n",
      "\n",
      "<answer>3 7 4 | 8 5 1 | 6 2 9\n",
      "1 5 8 | 6 9 2 | 4 3 7\n",
      "2 9 6 | 4 7 3 | 8 1 5\n",
      "------+-------+------\n",
      "8 1 7 | 5 2 6 | 9 4 3\n",
      "6 2 5 | 9 3 4 | 7 8 1\n",
      "4 3 9 | 7 1 8 | 5 6 2\n",
      "------+-------+------\n",
      "9 4 2 | 3 8 7 | 1 5 6\n",
      "5 6 1 | 2 4 9 | 3 7 8\n",
      "7 8 3 | 1 6 5 | 2 9 4</answer>\n"
     ]
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "\n",
    "# 测试微调后的模型\n",
    "print(\"\\n步骤8: 测试微调后的模型...\")\n",
    "if len(eval_dataset) > 0:\n",
    "    test_example = eval_dataset[2][\"text\"]\n",
    "    test_question = test_example.split(\"<|im_start|>user\\n\")[1].split(\"<|im_end|>\")[0]\n",
    "    finetuned_response = test_model(finetuned_model, finetuned_tokenizer, test_question)\n",
    "    print(\"问题：\")\n",
    "    print(test_question)\n",
    "    print(\"grpo模型回答示例:\")\n",
    "    print(finetuned_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
